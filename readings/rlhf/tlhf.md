## RLHF
[Illustrating Reinforcement Learning from Human Feedback (RLHF)](https://huggingface.co/blog/rlhf)

## Tools
[A modular RL library to fine-tune language models to human preferences](https://github.com/allenai/RL4LMs)