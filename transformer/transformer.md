## Papers
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
## Blogs
- [Attention](https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021)
   - learned self-attention 
   - scaled dot product
   - query, key, value
   - multi-head
- Other
## repos
