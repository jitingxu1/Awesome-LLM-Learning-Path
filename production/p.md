## concepts
- Continuous Batching [Anyscale blog](https://www.anyscale.com/blog/continuous-batching-llm-inference)[todo]
    - hugging face: text-generation-inference
    - vLLM: 23x inference throuput and reducing p50 latency
- PageAttention - vLLM [todo]