## Blogs
- [Fix Hallucination in Retrieval Augmented Generation AI Applications Using Schema and Output Parser](https://kelly-kang.medium.com/fix-hallucination-in-retrieval-augmented-generation-ai-applications-using-schema-and-output-parser-d58325daf1da)


## Learnings
- [in Context Learning (ICL)](https://www.hopsworks.ai/dictionary/in-context-learning-icl#:~:text=In%2Dcontext%20learning%20(ICL),the%20need%20for%20fine%2Dtuning.)
    - Add the most relavent context at the beginning or the end of a prompt improve the performance of LLMs, [researchers](https://arxiv.org/abs/2307.03172) have shown that adding relevant context in the middle of the prompt leads to worse performance. 
    - In-context learning benefits from larger context window sizes: the larger the context size, the better the performance is. Need to use LLm with large context size. 
- 